{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1. 编写一个类，支持读取文件，自动将train和test的数据集合并在一起，并且通过flag区分，支持指定label来自动生成y\n",
    "2. 可以定义几种常用的处理方式来处理特征，例如标准化和onehotcode等\n",
    "3. 自动分析变量和画图、慢慢来\n",
    "4. 能够设定评价指标后，自动进行CV测试\n",
    "5. 能够自动搜索最佳超参数，然后选取最好的那个\n",
    "6. 支持导出结果文件\n",
    "7. 支持多模型比较和融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score,mean_squared_error\n",
    "from sklearn.model_selection  import cross_val_score\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPipe:\n",
    "    # type_c_or_r: c  表示分类模型，r 表示回归模型\n",
    "    def __init__(self, train_file, test_file, y_col, id_col, type_c_or_r):\n",
    "        self.train_file = train_file\n",
    "        self.test_file = test_file\n",
    "        self.y_col = y_col\n",
    "        self.id_col = id_col\n",
    "        self.type_c_or_r = type_c_or_r\n",
    "        self.col_is_train = 'col_is_train'\n",
    "        self.mod_list = [] \n",
    "        self.rand_state = 43\n",
    "        self.ft_name = '' # 数据集名称 \n",
    "    \n",
    "    # 用来标识数据集的名字，主要用来输出结果文件名\n",
    "    def set_ft_name(self, ft_name):\n",
    "        self.ft_name = ft_name\n",
    "        \n",
    "    # 读取文件，然后合并两个文件\n",
    "    def parse_file(self):\n",
    "        self.src_train_df = pd.read_csv(self.train_file)\n",
    "        self.src_test_df = pd.read_csv(self.test_file)\n",
    "        \n",
    "        self.train_df = self.src_train_df.copy()\n",
    "        self.test_df = self.src_test_df.copy()\n",
    "        \n",
    "        # 设置test数据的y值为0，并且区分\n",
    "        self.test_df[self.y_col] = 0\n",
    "        self.test_df[self.col_is_train] = 0 \n",
    "        self.train_df[self.col_is_train] = 1\n",
    "        # 合并两个数据集，后续所有操作都在all_df中\n",
    "        self.all_df = pd.concat([self.train_df, self.test_df],ignore_index=True)\n",
    "        \n",
    "        self.print_shape()\n",
    "            \n",
    "    def print_shape(self):\n",
    "        print(\"Train Shape: %d:%d\" %(self.train_df.shape))\n",
    "        print(\"Test  Shape: %d:%d\" %(self.test_df.shape))\n",
    "        print(\"All   Shape: %d:%d\" %(self.all_df.shape))\n",
    "        \n",
    "    def split_X_y(self):\n",
    "        self.X_train = self.all_df[self.all_df[self.col_is_train] == 1]\n",
    "        self.y_train = self.X_train[self.y_col]\n",
    "        self.X_train = self.X_train.drop(self.y_col, axis=1)\n",
    "\n",
    "        self.X_test = self.all_df[self.all_df[self.col_is_train] == 0]\n",
    "        self.y_test = self.X_test[self.y_col]\n",
    "        self.X_test = self.X_test.drop(self.y_col, axis=1)\n",
    "        \n",
    "    #print(\"MSE:\",mean_squared_error(y_eval, y_pred))      \n",
    "    def get_model(self, model_name):\n",
    "        if model_name == 'RFR':\n",
    "            from sklearn.ensemble import RandomForestRegressor\n",
    "            # Fit regression model\n",
    "            mod = RandomForestRegressor(n_estimators=50, max_depth=5, random_state=self.rand_state)\n",
    "            res_file = 'f%s_m%s_n%d_d%s.csv' %(self.ft_name, model_name, mod.n_estimators,\n",
    "                                               mod.max_depth)\n",
    "            \n",
    "        if model_name == 'XGB_R':\n",
    "            params={\n",
    "                'n_estimators':100,\n",
    "                'objective': 'reg:linear', #回归问题 reg:linear 分类问题  binary:logistic  排序 rank:pairwise\n",
    "                'learning_rate': 0.007, # 学习率，默认0.1\n",
    "                'max_depth':6, # 构建树的深度，越大越容易过拟合.默认6 \n",
    "                'eval_metric': 'auc', # rmse mae logloss error auc \n",
    "                'gamma':0,  # 用于控制是否后剪枝的参数,越大越保守，一般0.1、0.2这样子。\n",
    "                'lambda':2,  # 控制模型复杂度的权重值的L2正则化项参数，参数越大，模型越不容易过拟合。\n",
    "                'subsample':1, # 随机采样训练样本，默认1\n",
    "                'min_child_weight':1, # 这个参数默认是 1，是每个叶子里面 h 的和至少是多少，对正负样本不均衡时的 0-1 分类而言\n",
    "                #，假设 h 在 0.01 附近，min_child_weight 为 1 意味着叶子节点中最少需要包含 100 个样本。\n",
    "                #这个参数非常影响结果，控制叶子节点中二阶导的和的最小值，该参数值越小，越容易 overfitting。 \n",
    "                'seed':819\n",
    "                }\n",
    "            #from sklearn.ensemble import XGBRegressor\n",
    "            mod = xgb.XGBRegressor(**params)\n",
    "            res_file = 'f%s_m%s_n%d_d%s.csv'  %(self.ft_name, model_name, mod.n_estimators,\n",
    "                                               mod.max_depth)\n",
    "            \n",
    "            if model_name == 'XGB_C':\n",
    "                params={\n",
    "                'n_estimators':100,\n",
    "                'objective': 'binary:logistic', #回归问题 reg:linear 分类问题  binary:logistic  排序 rank:pairwise\n",
    "                'learning_rate': 0.1, # 学习率，默认0.3\n",
    "                'max_depth':6, # 构建树的深度，越大越容易过拟合.默认6 \n",
    "                'eval_metric': 'auc', # rmse mae logloss error auc \n",
    "                'gamma':0,  # 用于控制是否后剪枝的参数,越大越保守，一般0.1、0.2这样子。\n",
    "                'lambda':2,  # 控制模型复杂度的权重值的L2正则化项参数，参数越大，模型越不容易过拟合。\n",
    "                'subsample':1, # 随机采样训练样本，默认1\n",
    "                'min_child_weight':1, # 这个参数默认是 1，是每个叶子里面 h 的和至少是多少，对正负样本不均衡时的 0-1 分类而言\n",
    "                #，假设 h 在 0.01 附近，min_child_weight 为 1 意味着叶子节点中最少需要包含 100 个样本。\n",
    "                #这个参数非常影响结果，控制叶子节点中二阶导的和的最小值，该参数值越小，越容易 overfitting。 \n",
    "                'seed':819\n",
    "                }\n",
    "                #from sklearn.ensemble import XGBRegressor\n",
    "                mod = xgb.XGBClassifier(**params)\n",
    "                res_file = 'f%s_m%s_n%d_d%s.csv'  %(self.ft_name, model_name, mod.n_estimators,\n",
    "                                               mod.max_depth)\n",
    "            \n",
    "        mod_parm = {}\n",
    "        mod_parm['name'] = model_name\n",
    "        mod_parm['mod'] = mod \n",
    "        mod_parm['res_file'] = res_file \n",
    "        return mod_parm\n",
    "    \n",
    "    def add_model(self, model_name):\n",
    "        mod_parm = self.get_model(model_name)\n",
    "        self.mod_list.append(mod_parm)\n",
    "        \n",
    "    def set_model(self, model_name):\n",
    "        mod_parm = self.get_model(model_name)\n",
    "        self.mod_list = []\n",
    "        self.mod_list.append(mod_parm)\n",
    "        \n",
    "    def cv_model(self):\n",
    "        for mod_parm in self.mod_list:\n",
    "            scores = cross_val_score(mod_parm['mod'], self.X_train, self.y_train, cv=5, scoring='r2')\n",
    "            mod_parm['score_mean'] = scores.mean()\n",
    "            mod_parm['score_std'] = scores.std()\n",
    "            print(\"Mod[%s]  R2: %0.6f (+/- %0.6f)\" % (mod_parm['name'], mod_parm['score_mean'], mod_parm['score_std']))\n",
    "            \n",
    "    def out_res_file(self):\n",
    "        for mod_parm in self.mod_list:\n",
    "            mod =  mod_parm['mod'].fit(self.X_train, self.y_train)\n",
    "            y_pred =  mod.predict(self.X_test)\n",
    "            output = pd.DataFrame({'id': self.X_test[self.id_col].astype(np.int32), self.y_col: y_pred})\n",
    "            out_file = mod_parm['res_file']\n",
    "            print('out_res_file to %s' %out_file)\n",
    "            output.to_csv(out_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fs_drop_col(df):\n",
    "    count_dict = {}\n",
    "    for col in df.columns:\n",
    "        #print(col)\n",
    "        arr_count = len(df[col].unique())\n",
    "        count_dict.setdefault(arr_count, [])\n",
    "        count_dict[arr_count].append(col)\n",
    "     \n",
    "    #for key,val in count_dict.items():\n",
    "     #   print key,val\n",
    "    \n",
    "    # 计算每个特征中最多变量所占比例\n",
    "    lc = [ df[col].value_counts().max() for col in df.columns ]\n",
    "    val_count = pd.Series(lc, index= df.columns )\n",
    "\n",
    "    # 删除不要的特征\n",
    "    #drop_col = count_dict[1]\n",
    "    drop_col = []\n",
    "    # drop_col.append('X4')\n",
    "    drop_col = drop_col + val_count.index[val_count>len(df)*0.98].tolist()\n",
    "\n",
    "    drop_col = list(set(drop_col))\n",
    "    df.drop(drop_col, axis=1, inplace=True)\n",
    "    #for col in set(drop_col):\n",
    "        #print col \n",
    "        #df.drop(col, axis=1, inplace=True)\n",
    "\n",
    "    df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fs_drop_row(df):\n",
    "    df.drop(df.index[df.y == df.y.max()], inplace=True)\n",
    "    \n",
    "def fs_dummpy(df):\n",
    "    return pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: 4209:379\nTest  Shape: 4209:379\nAll   Shape: 8418:379\n"
     ]
    }
   ],
   "source": [
    "ml = MLPipe(train_file='./car/train.csv', test_file='./car/test.csv', \n",
    "            y_col='y', id_col='ID', type_c_or_r='r')\n",
    "print(ml.id_col)\n",
    "ml.parse_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 8418 entries, 0 to 8417\nColumns: 200 entries, ID to y\ndtypes: float64(1), int64(192), object(7)\nmemory usage: 12.8+ MB\nTrain Shape: 4209:379\nTest  Shape: 4209:379\nAll   Shape: 8418:400\n"
     ]
    }
   ],
   "source": [
    "fs_drop_col(ml.all_df)\n",
    "#fs_drop_row(ml.all_df)\n",
    "ml.all_df = fs_dummpy(ml.all_df)\n",
    "ml.set_ft_name('dummy')\n",
    "ml.print_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.split_X_y()\n",
    "#ml.set_model('RFR')\n",
    "ml.set_model('XGB')\n",
    "#ml.cv_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out_res_file to fdummy_mXGB_n1000_d2.csv\n"
     ]
    }
   ],
   "source": [
    "ml.out_res_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n1 1\n2 2\n3 3\n"
     ]
    }
   ],
   "source": [
    "for i, ind in enumerate(list(range(4))):\n",
    "    print i,ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4209, 399)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml.X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_score': 0.5,\n 'colsample_bylevel': 1,\n 'colsample_bytree': 1,\n 'gamma': 0,\n 'learning_rate': 0.1,\n 'max_delta_step': 0,\n 'max_depth': 3,\n 'min_child_weight': 1,\n 'missing': None,\n 'n_estimators': 100,\n 'nthread': -1,\n 'objective': 'reg:linear',\n 'reg_alpha': 0,\n 'reg_lambda': 1,\n 'scale_pos_weight': 1,\n 'seed': 0,\n 'silent': True,\n 'subsample': 1}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml.mod_list[1]['mod'].get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:   23.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:   59.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:  1.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed:  2.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed:  4.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:  6.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  9.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed: 12.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed: 14.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n       estimator=XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n       gamma=0, learning_rate=0.01, max_delta_step=0, max_depth=3,\n       min_child_weight=1, missing=None, n_estimators=1000, nthread=-1,\n       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n       scale_pos_weight=1, seed=0, silent=True, subsample=0.8),\n       fit_params={}, iid=True, n_jobs=2,\n       param_grid={'max_depth': [2, 3, 4, 5, 6], 'min_child_weight': [1, 5]},\n       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n       scoring=None, verbose=10)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "cv_params = {'max_depth': [2,3,4,5,6], 'min_child_weight': [1,5]}\n",
    "ind_params = {'learning_rate': 0.01, 'n_estimators': 1000, \n",
    "              'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8,\n",
    "             'reg_alpha':0, 'reg_lambda':1} #regularization => L1 : alpha, L2 : lambda\n",
    "clt = xgb.XGBRegressor(**ind_params)\n",
    "\n",
    "optimized_GBM = GridSearchCV(clt, \n",
    "                             cv_params,  \n",
    "                             cv = 5, verbose=10,\n",
    "                             n_jobs = 2)\n",
    "optimized_GBM.fit(ml.X_train, ml.y_train)\n",
    "#optimized_GBM.grid_scores_\n",
    "optimized_GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n       learning_rate=0.1, max_delta_step=0, max_depth=3,\n       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n       scale_pos_weight=1, seed=0, silent=True, subsample=1)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized_GBM.best_params_\n",
    "#optimized_GBM.best_estimator_\n",
    "\n",
    "ml.mod_list[1]['mod']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 22.13940001,  19.81980009,  27.28840003,  26.69040003,\n         31.84960003,  33.41399999,  40.33579998,  39.01080003,\n         46.83200006,  48.64400001]),\n 'mean_score_time': array([ 0.0566    ,  0.04359989,  0.04319997,  0.04139996,  0.03980002,\n         0.05380006,  0.05660005,  0.04879999,  0.05159998,  0.05079999]),\n 'mean_test_score': array([ 0.49864456,  0.52326292,  0.44414339,  0.48678984,  0.41074115,\n         0.46114118,  0.37334339,  0.43046364,  0.27229416,  0.42463209]),\n 'mean_train_score': array([ 0.60930927,  0.60262171,  0.65474553,  0.63972517,  0.70270241,\n         0.6786426 ,  0.74995286,  0.71821972,  0.79545233,  0.75475748]),\n 'param_max_depth': masked_array(data = [2 2 3 3 4 4 5 5 6 6],\n              mask = [False False False False False False False False False False],\n        fill_value = ?),\n 'param_min_child_weight': masked_array(data = [1 5 1 5 1 5 1 5 1 5],\n              mask = [False False False False False False False False False False],\n        fill_value = ?),\n 'params': ({'max_depth': 2, 'min_child_weight': 1},\n  {'max_depth': 2, 'min_child_weight': 5},\n  {'max_depth': 3, 'min_child_weight': 1},\n  {'max_depth': 3, 'min_child_weight': 5},\n  {'max_depth': 4, 'min_child_weight': 1},\n  {'max_depth': 4, 'min_child_weight': 5},\n  {'max_depth': 5, 'min_child_weight': 1},\n  {'max_depth': 5, 'min_child_weight': 5},\n  {'max_depth': 6, 'min_child_weight': 1},\n  {'max_depth': 6, 'min_child_weight': 5}),\n 'rank_test_score': array([ 2,  1,  5,  3,  8,  4,  9,  6, 10,  7]),\n 'split0_test_score': array([ 0.35076621,  0.38809131,  0.26036987,  0.23854867,  0.20117178,\n         0.13576785,  0.03683368,  0.00272642, -0.4682945 , -0.01054313]),\n 'split0_train_score': array([ 0.61252311,  0.60000429,  0.658325  ,  0.63790571,  0.70370388,\n         0.6770165 ,  0.75291617,  0.71749807,  0.79839189,  0.75312145]),\n 'split1_test_score': array([ 0.44014285,  0.43973222,  0.43814064,  0.43669238,  0.43524581,\n         0.43414616,  0.43291635,  0.43309189,  0.43225213,  0.43063279]),\n 'split1_train_score': array([ 0.64229701,  0.63702818,  0.67393126,  0.66470213,  0.71305645,\n         0.6971918 ,  0.75279529,  0.73233724,  0.79481146,  0.76546311]),\n 'split2_test_score': array([ 0.59943807,  0.59876444,  0.60031883,  0.59860242,  0.60116544,\n         0.59674335,  0.59993606,  0.59353473,  0.59753029,  0.59125793]),\n 'split2_train_score': array([ 0.59666008,  0.5916142 ,  0.64701766,  0.63083619,  0.69859057,\n         0.67112979,  0.74522798,  0.71301776,  0.79199292,  0.75149918]),\n 'split3_test_score': array([ 0.54272286,  0.5419333 ,  0.53492135,  0.53397711,  0.53082107,\n         0.52981567,  0.52610941,  0.52511959,  0.52029005,  0.51817789]),\n 'split3_train_score': array([ 0.6121181 ,  0.60641859,  0.66022314,  0.64624303,  0.71187289,\n         0.68555028,  0.76015035,  0.72277631,  0.80356019,  0.75994684]),\n 'split4_test_score': array([ 0.56022593,  0.64794139,  0.38689829,  0.62629432,  0.28515248,\n         0.60940896,  0.27079965,  0.59804458,  0.27970164,  0.59383591]),\n 'split4_train_score': array([ 0.58294804,  0.5780433 ,  0.63423057,  0.61893877,  0.68628825,\n         0.66232464,  0.7386745 ,  0.70546923,  0.78850519,  0.74375685]),\n 'std_fit_time': array([ 5.04123145,  3.76140687,  5.60309709,  5.02388628,  4.4480594 ,\n         4.56610411,  6.55840878,  6.71000242,  7.89027763,  8.7479455 ]),\n 'std_score_time': array([ 0.02415452,  0.01116425,  0.00798494,  0.00422379,  0.00271283,\n         0.00620971,  0.01843475,  0.00530667,  0.00811426,  0.01457948]),\n 'std_test_score': array([ 0.09076368,  0.09678346,  0.11809303,  0.14023114,  0.14898358,\n         0.17418032,  0.20100753,  0.22209303,  0.38511545,  0.2256479 ]),\n 'std_train_score': array([ 0.01980569,  0.01964859,  0.01335284,  0.01536704,  0.00978405,\n         0.01197624,  0.00735358,  0.00905785,  0.00519652,  0.00742761])}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized_GBM.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid scores on development set:\n()\n0.499 (+/-0.182) for {'max_depth': 2, 'min_child_weight': 1}\n0.523 (+/-0.194) for {'max_depth': 2, 'min_child_weight': 5}\n0.444 (+/-0.236) for {'max_depth': 3, 'min_child_weight': 1}\n0.487 (+/-0.280) for {'max_depth': 3, 'min_child_weight': 5}\n0.411 (+/-0.298) for {'max_depth': 4, 'min_child_weight': 1}\n0.461 (+/-0.348) for {'max_depth': 4, 'min_child_weight': 5}\n0.373 (+/-0.402) for {'max_depth': 5, 'min_child_weight': 1}\n0.430 (+/-0.444) for {'max_depth': 5, 'min_child_weight': 5}\n0.272 (+/-0.770) for {'max_depth': 6, 'min_child_weight': 1}\n0.425 (+/-0.451) for {'max_depth': 6, 'min_child_weight': 5}\n()\n"
     ]
    }
   ],
   "source": [
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = optimized_GBM.cv_results_['mean_test_score']\n",
    "stds = optimized_GBM.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, optimized_GBM.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.5982, 'X314'),\n (0.1099, 'X315'),\n (0.044, 'X118'),\n (0.0409, 'X263'),\n (0.0398, 'X119'),\n (0.0196, 'X136'),\n (0.0194, 'ID'),\n (0.015, 'X29'),\n (0.014, 'X127'),\n (0.0121, 'X279'),\n (0.0091, 'X189'),\n (0.0068, 'X76'),\n (0.0068, 'X5_ag'),\n (0.0061, 'X232'),\n (0.0047, 'X54'),\n (0.0034, 'X1_f'),\n (0.0032, 'X5_q'),\n (0.0022, 'X6_c'),\n (0.002, 'X6_k'),\n (0.0015, 'X345')]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_names = ml.X_train.columns.values\n",
    "importances = ml.mod_list[0]['mod'].feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "indices[:20].tolist()\n",
    "ml.X_train.columns.values[indices[:20].tolist()]\n",
    "\n",
    "sort_list = sorted(zip(map(lambda x: round(x, 4), importances), feat_names), reverse=True)\n",
    "sort_list[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'mod': RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=5,\n             max_features='auto', max_leaf_nodes=None,\n             min_impurity_split=1e-07, min_samples_leaf=1,\n             min_samples_split=2, min_weight_fraction_leaf=0.0,\n             n_estimators=50, n_jobs=1, oob_score=False, random_state=43,\n             verbose=0, warm_start=False), 'name': 'RFR'}]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml.mod_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64      1\nint64      128\nobject       7\ndtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml.all_df.describe()\n",
    "ml.all_df.get_dtype_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>X10</th>\n",
       "      <th>X11</th>\n",
       "      <th>X12</th>\n",
       "      <th>X13</th>\n",
       "      <th>X14</th>\n",
       "      <th>X15</th>\n",
       "      <th>X16</th>\n",
       "      <th>X17</th>\n",
       "      <th>X18</th>\n",
       "      <th>...</th>\n",
       "      <th>X377</th>\n",
       "      <th>X378</th>\n",
       "      <th>X379</th>\n",
       "      <th>X380</th>\n",
       "      <th>X382</th>\n",
       "      <th>X383</th>\n",
       "      <th>X384</th>\n",
       "      <th>X385</th>\n",
       "      <th>y</th>\n",
       "      <th>col_is_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4209.000000</td>\n",
       "      <td>4209.000000</td>\n",
       "      <td>4209.000000</td>\n",
       "      <td>4209.000000</td>\n",
       "      <td>4209.000000</td>\n",
       "      <td>4209.000000</td>\n",
       "      <td>4209.000000</td>\n",
       "      <td>4209.000000</td>\n",
       "      <td>4209.000000</td>\n",
       "      <td>4209.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4209.000000</td>\n",
       "      <td>4209.000000</td>\n",
       "      <td>4209.000000</td>\n",
       "      <td>4209.000000</td>\n",
       "      <td>4209.000000</td>\n",
       "      <td>4209.000000</td>\n",
       "      <td>4209.000000</td>\n",
       "      <td>4209.000000</td>\n",
       "      <td>4209.0</td>\n",
       "      <td>4209.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4211.039202</td>\n",
       "      <td>0.019007</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.074364</td>\n",
       "      <td>0.061060</td>\n",
       "      <td>0.427893</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>0.002613</td>\n",
       "      <td>0.008791</td>\n",
       "      <td>0.010216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.311951</td>\n",
       "      <td>0.019244</td>\n",
       "      <td>0.011879</td>\n",
       "      <td>0.008078</td>\n",
       "      <td>0.008791</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2423.078926</td>\n",
       "      <td>0.136565</td>\n",
       "      <td>0.015414</td>\n",
       "      <td>0.262394</td>\n",
       "      <td>0.239468</td>\n",
       "      <td>0.494832</td>\n",
       "      <td>0.026691</td>\n",
       "      <td>0.051061</td>\n",
       "      <td>0.093357</td>\n",
       "      <td>0.100570</td>\n",
       "      <td>...</td>\n",
       "      <td>0.463345</td>\n",
       "      <td>0.137399</td>\n",
       "      <td>0.108356</td>\n",
       "      <td>0.089524</td>\n",
       "      <td>0.093357</td>\n",
       "      <td>0.021796</td>\n",
       "      <td>0.026691</td>\n",
       "      <td>0.040752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2115.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4202.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6310.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8416.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>X10</th>\n",
       "      <th>X11</th>\n",
       "      <th>X12</th>\n",
       "      <th>X13</th>\n",
       "      <th>X14</th>\n",
       "      <th>X15</th>\n",
       "      <th>X16</th>\n",
       "      <th>X17</th>\n",
       "      <th>X18</th>\n",
       "      <th>...</th>\n",
       "      <th>X377</th>\n",
       "      <th>X378</th>\n",
       "      <th>X379</th>\n",
       "      <th>X380</th>\n",
       "      <th>X382</th>\n",
       "      <th>X383</th>\n",
       "      <th>X384</th>\n",
       "      <th>X385</th>\n",
       "      <th>y</th>\n",
       "      <th>col_is_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4209.000000</td>\n",
       "      <td>4209.000000</td>\n",
       "      <td>4209.000000</td>\n",
       "      <td>4209.000000</td>\n",
       "      <td>4209.000000</td>\n",
       "      <td>4209.000000</td>\n",
       "      <td>4209.000000</td>\n",
       "      <td>4209.000000</td>\n",
       "      <td>4209.000000</td>\n",
       "      <td>4209.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4209.000000</td>\n",
       "      <td>4209.000000</td>\n",
       "      <td>4209.000000</td>\n",
       "      <td>4209.000000</td>\n",
       "      <td>4209.000000</td>\n",
       "      <td>4209.000000</td>\n",
       "      <td>4209.000000</td>\n",
       "      <td>4209.000000</td>\n",
       "      <td>4209.0</td>\n",
       "      <td>4209.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4211.039202</td>\n",
       "      <td>0.019007</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.074364</td>\n",
       "      <td>0.061060</td>\n",
       "      <td>0.427893</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>0.002613</td>\n",
       "      <td>0.008791</td>\n",
       "      <td>0.010216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.311951</td>\n",
       "      <td>0.019244</td>\n",
       "      <td>0.011879</td>\n",
       "      <td>0.008078</td>\n",
       "      <td>0.008791</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2423.078926</td>\n",
       "      <td>0.136565</td>\n",
       "      <td>0.015414</td>\n",
       "      <td>0.262394</td>\n",
       "      <td>0.239468</td>\n",
       "      <td>0.494832</td>\n",
       "      <td>0.026691</td>\n",
       "      <td>0.051061</td>\n",
       "      <td>0.093357</td>\n",
       "      <td>0.100570</td>\n",
       "      <td>...</td>\n",
       "      <td>0.463345</td>\n",
       "      <td>0.137399</td>\n",
       "      <td>0.108356</td>\n",
       "      <td>0.089524</td>\n",
       "      <td>0.093357</td>\n",
       "      <td>0.021796</td>\n",
       "      <td>0.026691</td>\n",
       "      <td>0.040752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2115.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4202.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6310.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8416.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 371 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml.test_df.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}